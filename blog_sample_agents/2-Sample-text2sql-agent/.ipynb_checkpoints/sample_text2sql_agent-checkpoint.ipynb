{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Text2SQL Agent Walkthrough\n",
    "\n",
    "This notebook will walk users through setting up a generic Text2SQL Agent and run it against the BirdSQL - Mini Dev Dataset (https://github.com/bird-bench/mini_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure the latest version of boto3 is shown below\n",
    "\n",
    "##### If not then run through setup_environment.ipynb in the 0-Notebook-environment/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3==1.36.24\n",
      "pandas==1.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep -E \"boto3|pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in environment variables to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve import path\n",
    "%store -r IMPORTS_PATH\n",
    "\n",
    "# Retrieve account info\n",
    "%store -r account_id\n",
    "%store -r region\n",
    "\n",
    "# Retrieve model lists\n",
    "%store -r agent_foundation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the variables in os\n",
    "os.environ['REGION'] = region\n",
    "os.environ['BASE_BUCKET_NAME'] = 'text2sql-agent'\n",
    "os.environ['ATHENA_RESULTS_BUCKET_NAME'] = 'text2sql-athena-results'\n",
    "os.environ['BASE_DIR'] = 'dev_databases'\n",
    "os.environ['DATABASE_NAME'] = 'california_schools'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve BirdSQL - Mini Dev Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 0: cd: 2-Sample-text2sql-agent: No such file or directory\n",
      "--2025-02-21 18:04:43--  https://bird-bench.oss-cn-beijing.aliyuncs.com/dev.zip\n",
      "8.141.181.247d-bench.oss-cn-beijing.aliyuncs.com (bird-bench.oss-cn-beijing.aliyuncs.com)... \n",
      "connected. to bird-bench.oss-cn-beijing.aliyuncs.com (bird-bench.oss-cn-beijing.aliyuncs.com)|8.141.181.247|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 346207293 (330M) [application/zip]\n",
      "Saving to: ‘dev.zip’\n",
      "\n",
      "100%[======================================>] 346,207,293 14.2MB/s   in 22s    \n",
      "\n",
      "2025-02-21 18:05:05 (15.3 MB/s) - ‘dev.zip’ saved [346207293/346207293]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download .zip file to local directory\n",
    "\n",
    "!cd 2-Sample-text2sql-agent\n",
    "!wget https://bird-bench.oss-cn-beijing.aliyuncs.com/dev.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Necessary services to run Text2SQL agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the Text2SQL agent, we will need to setup the Athena databases to make SQL queries against. The following script will:\n",
    "1. Unzip the downloaded folder\n",
    "2. Create S3 buckets\n",
    "3. Convert .sqlite files into individual .parquet files for each table\n",
    "4. Upload to the database s3 bucket\n",
    "5. Set up appropriate Athena permissions\n",
    "6. Create databases in Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created input.json for agent\n"
     ]
    }
   ],
   "source": [
    "%run data_prep.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Text2SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get boto3 clients for required AWS services\n",
    "sts_client = boto3.client('sts')\n",
    "iam_client = boto3.client('iam')\n",
    "s3_client = boto3.client('s3')\n",
    "lambda_client = boto3.client('lambda')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('us-west-2', '761018876800')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random prefix for unique IAM roles, agent name and S3 Bucket and \n",
    "# assign variables\n",
    "suffix = f\"{region}-{account_id}\"\n",
    "agent_name = \"sample-text2sql-agent\"\n",
    "agent_alias_name = \"sample-alias\"\n",
    "bucket_name = f'{agent_name}-{suffix}'\n",
    "bucket_key = f'{agent_name}-schema.json'\n",
    "schema_name = 'sample_text2sql_agent_openapi_schema.json'\n",
    "schema_arn = f'arn:aws:s3:::{bucket_name}/{bucket_key}'\n",
    "bedrock_agent_bedrock_allow_policy_name = f\"{agent_name}-allow-{suffix}\"\n",
    "bedrock_agent_s3_allow_policy_name = f\"{agent_name}-s3-allow-{suffix}\"\n",
    "lambda_role_name = f'{agent_name}-lambda-role-{suffix}'\n",
    "agent_role_name = f'AmazonBedrockExecutionRoleForAgents_{suffix}'\n",
    "lambda_code_path = \"lambda_function.py\"\n",
    "lambda_name = f'{agent_name}-{suffix}'\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create S3 bucket and upload API Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 bucket for Open API schema\n",
    "if region == \"us-east-1\":\n",
    "    s3bucket = s3_client.create_bucket(\n",
    "        Bucket=bucket_name\n",
    "    )\n",
    "else:\n",
    "    s3bucket = s3_client.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={ 'LocationConstraint': region } \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload Open API Schema to s3 bucket\n",
    "s3_client.upload_file(schema_name, bucket_name, bucket_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Lambda function for Action Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f9e17745-6ef6-4225-8a6b-c211c177acb1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 14 Feb 2025 21:22:07 GMT',\n",
       "   'x-amzn-requestid': 'f9e17745-6ef6-4225-8a6b-c211c177acb1',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '212'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create IAM Role for the Lambda function\n",
    "try:\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"lambda.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    assume_role_policy_document_json = json.dumps(assume_role_policy_document)\n",
    "\n",
    "    lambda_iam_role = iam_client.create_role(\n",
    "        RoleName=lambda_role_name,\n",
    "        AssumeRolePolicyDocument=assume_role_policy_document_json\n",
    "    )\n",
    "\n",
    "    # Pause to make sure role is created\n",
    "    time.sleep(10)\n",
    "except:\n",
    "    lambda_iam_role = iam_client.get_role(RoleName=lambda_role_name)\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=lambda_role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package up the lambda function code\n",
    "s = BytesIO()\n",
    "z = zipfile.ZipFile(s, 'w')\n",
    "z.write(lambda_code_path)\n",
    "z.close()\n",
    "zip_content = s.getvalue()\n",
    "\n",
    "# Create Lambda Function\n",
    "lambda_function = lambda_client.create_function(\n",
    "    FunctionName=lambda_name,\n",
    "    Runtime='python3.12',\n",
    "    Timeout=180,\n",
    "    Role=lambda_iam_role['Role']['Arn'],\n",
    "    Code={'ZipFile': zip_content},\n",
    "    Handler='lambda_function.lambda_handler'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IAM policies for agent\n",
    "\n",
    "bedrock_agent_bedrock_allow_policy_statement = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AmazonBedrockAgentBedrockFoundationModelPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"bedrock:InvokeModel\",\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:bedrock:{region}::foundation-model/{model_id}\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "bedrock_policy_json = json.dumps(bedrock_agent_bedrock_allow_policy_statement)\n",
    "\n",
    "agent_bedrock_policy = iam_client.create_policy(\n",
    "    PolicyName=bedrock_agent_bedrock_allow_policy_name,\n",
    "    PolicyDocument=bedrock_policy_json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy that allows fetching of agent's OpenAPI schema from S3\n",
    "\n",
    "bedrock_agent_s3_allow_policy_statement = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AllowAgentAccessOpenAPISchema\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\"s3:GetObject\"],\n",
    "            \"Resource\": [\n",
    "                schema_arn\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "bedrock_agent_s3_json = json.dumps(bedrock_agent_s3_allow_policy_statement)\n",
    "agent_s3_schema_policy = iam_client.create_policy(\n",
    "    PolicyName=bedrock_agent_s3_allow_policy_name,\n",
    "    Description=f\"Policy to allow invoke Lambda that was provisioned for it.\",\n",
    "    PolicyDocument=bedrock_agent_s3_json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'da2e77fa-3d49-4299-b255-e78f2f1fee76',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Mon, 17 Feb 2025 21:26:54 GMT',\n",
       "   'x-amzn-requestid': 'da2e77fa-3d49-4299-b255-e78f2f1fee76',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '212'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create IAM Role for the agent and attach IAM policies\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"bedrock.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "assume_role_policy_document_json = json.dumps(assume_role_policy_document)\n",
    "agent_role = iam_client.create_role(\n",
    "    RoleName=agent_role_name,\n",
    "    AssumeRolePolicyDocument=assume_role_policy_document_json\n",
    ")\n",
    "\n",
    "# Pause to make sure role is created\n",
    "time.sleep(10)\n",
    "    \n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=agent_role_name,\n",
    "    PolicyArn=agent_bedrock_policy['Policy']['Arn']\n",
    ")\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=agent_role_name,\n",
    "    PolicyArn=agent_s3_schema_policy['Policy']['Arn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_foundation_model = \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "agent_description = \"Text2SQL agent to run against Bird-SQL Mini-Dev benchmark dataset\"\n",
    "agent_instruction = \"\"\"\n",
    "You are an AI Agent specialized in generating SQL queries for a database. \n",
    "Your primary task is to interpret user queries, \n",
    "generate appropriate SQL queries, and provide relevant answer based on the data. \n",
    "Use only the appropriate tools as required by the specific question. Follow these instructions carefully: \n",
    "1. Before generating any SQL query, use the /getschema tool to familiarize yourself with the database structure. \n",
    "This will ensure your queries are correctly formatted and target the appropriate columns. \n",
    "2. When generating an SQL query: a. Write the query as a single line, removing all newline (\"\n",
    "\") characters. \n",
    "b. Column names should remain consistent, do not modify the column names in the generated SQL query. \n",
    "3. When providing your response: a. Start with a brief summary of your understanding of \n",
    "the user's query. b. Explain the steps you're taking to address the query. c. Ask for clarifications from the \n",
    "user if required.\n",
    "\"\"\"\n",
    "\n",
    "response = bedrock_agent_client.create_agent(\n",
    "    agentName=agent_name,\n",
    "    description=agent_description,\n",
    "    instruction=agent_instruction,\n",
    "    foundationModel=agent_foundation_model,\n",
    "    agentResourceRoleArn=agent_role['Role']['Arn']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AQIMYSEPOK', 'arn:aws:bedrock:us-west-2:761018876800:agent/AQIMYSEPOK')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_id = response['agent']['agentId']\n",
    "agent_arn = response['agent']['agentArn']\n",
    "agent_id , agent_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Agent Action Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:lambda:us-west-2:761018876800:function:sample-text2sql-agent-us-west-2-761018876800\n",
      "sample-text2sql-agent-us-west-2-761018876800 sample-text2sql-agent-schema.json\n"
     ]
    }
   ],
   "source": [
    "# Pause to make sure agent is created\n",
    "# time.sleep(30)\n",
    "# Now, we can configure and create an action group here:\n",
    "\n",
    "print(lambda_function['FunctionArn'])\n",
    "print(bucket_name, bucket_key)\n",
    "\n",
    "# Use agent helper to clean up\n",
    "agent_action_group_response = bedrock_agent_client.create_agent_action_group(\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    actionGroupExecutor={\n",
    "        'lambda': lambda_function['FunctionArn']\n",
    "        # 'roleArn': 'arn:aws:iam::761018876800:role/sample-text2sql-agent-lambda-role-us-west-2-761018876800',  # Add your IAM role ARN here\n",
    "        # 'roleSessionName': 'BedrockAgentSession'  # Add a session name\n",
    "    },\n",
    "    actionGroupName='QueryAthena',\n",
    "    apiSchema={\n",
    "        's3': {\n",
    "            's3BucketName': bucket_name,\n",
    "            's3ObjectKey': bucket_key\n",
    "        }\n",
    "    },\n",
    "    description='Execute SQL queries in Athena database'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create allow invoke permission on lambda\n",
    "response = lambda_client.add_permission(\n",
    "    FunctionName=lambda_name,\n",
    "    StatementId='allow_bedrock',\n",
    "    Action='lambda:InvokeFunction',\n",
    "    Principal='bedrock.amazonaws.com',\n",
    "    SourceArn=f\"arn:aws:bedrock:{region}:{account_id}:agent/{agent_id}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '194cea38-3947-4aee-ad01-3b86d494664b',\n",
       "  'HTTPStatusCode': 202,\n",
       "  'HTTPHeaders': {'date': 'Mon, 17 Feb 2025 21:53:32 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '119',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '194cea38-3947-4aee-ad01-3b86d494664b',\n",
       "   'x-amz-apigw-id': 'GJhqhGNGvHcEADA=',\n",
       "   'x-amzn-trace-id': 'Root=1-67b3afdc-63233e2f37f3a60e3d0eacee'},\n",
       "  'RetryAttempts': 0},\n",
       " 'agentId': 'AQIMYSEPOK',\n",
       " 'agentStatus': 'PREPARING',\n",
       " 'agentVersion': 'DRAFT',\n",
       " 'preparedAt': datetime.datetime(2025, 2, 17, 21, 53, 32, 819336, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_prepare = bedrock_agent_client.prepare_agent(agentId=agent_id)\n",
    "agent_prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Agent Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pause to make sure agent is prepared\n",
    "# time.sleep(30)\n",
    "agent_alias = bedrock_agent_client.create_agent_alias(\n",
    "    agentId=agent_id,\n",
    "    agentAliasName=agent_alias_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T9J04ATBNJ'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time.sleep(30)\n",
    "# Extract the agentAliasId from the response\n",
    "agent_alias_id = agent_alias['agentAlias']['agentAliasId']\n",
    "\n",
    "agent_alias_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a random id for session initiator id\n",
    "session_id:str = str(uuid.uuid1())\n",
    "\n",
    "# invoke the agent API\n",
    "agentResponse = bedrock_agent_runtime_client.invoke_agent(\n",
    "    inputText=\"what are the open claims?\",\n",
    "    agentId=agent_id,\n",
    "    agentAliasId=agent_alias_id, \n",
    "    sessionId=session_id,\n",
    "    enableTrace=True,\n",
    "    endSession=False,\n",
    "    sessionState={}\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Request sent to Agent:\\n{}\".format(response))\n",
    "print(\"====================\")\n",
    "print(\"Agent processing query now\")\n",
    "print(\"====================\")\n",
    "\n",
    "# Initialize an empty string to store the answer\n",
    "answer = \"\"\n",
    "\n",
    "# Iterate through the event stream\n",
    "for event in response['completion']:\n",
    "    # Check if the event is a 'chunk' event\n",
    "    if 'chunk' in event:\n",
    "        chunk_obj = event['chunk']\n",
    "        if 'bytes' in chunk_obj:\n",
    "            # Decode the bytes and append to the answer\n",
    "            chunk_data = chunk_obj['bytes'].decode('utf-8')\n",
    "            answer += chunk_data\n",
    "\n",
    "# Now 'answer' contains the full response from the agent\n",
    "print(\"Agent Answer: {}\".format(answer))\n",
    "print(\"====================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input .json file for all Text2SQL using ground truth provided by BirdSQL Mini-Dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('text2sql-athena-results', 'california_schools')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATHENA_RESULTS_BUCKET_NAME = os.environ.get('ATHENA_RESULTS_BUCKET_NAME')\n",
    "DATABASE_NAME = os.environ.get('DATABASE_NAME')\n",
    "\n",
    "ATHENA_RESULTS_BUCKET_NAME, DATABASE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing question 0: What is the highest eligible free rate for K-12 students in the schools in Alameda County?\n",
      "Generated ground truth for question 0\n",
      "\n",
      "Processing question 1: Please list the lowest three eligible free rates for students aged 5-17 in continuation schools.\n",
      "Generated ground truth for question 1\n",
      "\n",
      "Processing question 2: Please list the zip code of all the charter schools in Fresno County Office of Education.\n",
      "Generated ground truth for question 2\n",
      "\n",
      "Processing question 3: What is the unabbreviated mailing street address of the school with the highest FRPM count for K-12 students?\n",
      "Generated ground truth for question 3\n",
      "\n",
      "Processing question 4: Please list the phone numbers of the direct charter-funded schools that are opened after 2000/1/1.\n",
      "Generated ground truth for question 4\n",
      "\n",
      "Processed 5 questions. Results saved to text2sql_data_file_auto.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def run_query(query: str, athena_client):\n",
    "    \"\"\"\n",
    "    Run Athena query and return results as pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = athena_client.start_query_execution(\n",
    "            QueryString=query,\n",
    "            QueryExecutionContext={\n",
    "                'Database': DATABASE_NAME\n",
    "            },\n",
    "            ResultConfiguration={\n",
    "                'OutputLocation': f's3://{ATHENA_RESULTS_BUCKET_NAME}/athena-results/'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        query_execution_id = response['QueryExecutionId']\n",
    "        \n",
    "        while True:\n",
    "            response = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "            state = response['QueryExecution']['Status']['State']\n",
    "            \n",
    "            if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "                break\n",
    "                \n",
    "            time.sleep(1)\n",
    "            \n",
    "        if state == 'SUCCEEDED':\n",
    "            response = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "            # Process data\n",
    "            results = []\n",
    "            for row in response['ResultSet']['Rows'][1:]:  # Skip header row\n",
    "                for field in row['Data']:\n",
    "                    value = field.get('VarCharValue', '')\n",
    "                    \n",
    "                    results.append(str(value))\n",
    "            \n",
    "            # Join results with commas\n",
    "            return ', '.join(results)\n",
    "        else:\n",
    "            print(f\"Query failed with state: {state}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error running query: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_ground_truth_answer(question_id: int, question: str, sql_query: str, \n",
    "                               sql_context: str, query_results: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate ground truth answer using AWS Bedrock based on question and query results\n",
    "    \"\"\"\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name='bedrock-runtime'\n",
    "    )\n",
    "        \n",
    "    # Construct prompt for Bedrock\n",
    "    prompt = f\"\"\"You are generating ground truth answers that will be used to evaluate the factual correctness of Text2SQL agent responses.\n",
    "\n",
    "Question: {question}\n",
    "Query Results: {query_results}\n",
    "\n",
    "Generate a natural language answer that:\n",
    "1. States all numerical values and facts from the query results explicitly\n",
    "2. Uses consistent formatting for numbers (maintain exact precision from results)\n",
    "3. Includes all relevant values if multiple results are returned\n",
    "4. States the answer in a clear, declarative way that directly addresses the question\n",
    "5. Avoids additional interpretations or information not present in the query results\n",
    "\n",
    "Remember:\n",
    "- Focus only on the facts present in the query results\n",
    "- Use the exact numbers shown in the results\n",
    "- Structure the answer to make fact-checking straightforward\n",
    "- Be explicit about any percentages, counts, or measurements\n",
    "- Make sure every number in the query results is mentioned in your answer\n",
    "\n",
    "Your answer should be easy to compare with other responses for factual accuracy.\"\"\"\n",
    "\n",
    "    # Create request body for Claude model\n",
    "    body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "            }\n",
    "        ],\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        # Call Bedrock\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',  # or your preferred model\n",
    "            body=body\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        answer = response_body['content'][0]['text']\n",
    "        \n",
    "        # Format the response in the required structure\n",
    "        formatted_response = {\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question,\n",
    "            \"question_type\": \"TEXT2SQL\",\n",
    "            \"ground_truth\": {\n",
    "                \"ground_truth_sql_query\": sql_query,\n",
    "                \"ground_truth_sql_context\": sql_context,\n",
    "                \"ground_truth_query_result\": query_results,\n",
    "                \"ground_truth_answer\": answer\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return formatted_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return None\n",
    "\n",
    "        \n",
    "def get_schema(athena_client):\n",
    "    \"\"\"\n",
    "    Get schema information for all tables in Athena databases\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            table_name,\n",
    "            column_name,\n",
    "            data_type\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = '{DATABASE_NAME}'\n",
    "        ORDER BY table_name, ordinal_position;\n",
    "        \"\"\"\n",
    "        \n",
    "    try:\n",
    "        # Start query execution\n",
    "        response = athena_client.start_query_execution(\n",
    "            QueryString=sql,\n",
    "            QueryExecutionContext={\n",
    "                'Database': DATABASE_NAME\n",
    "            }\n",
    "        )\n",
    "            \n",
    "        query_execution_id = response['QueryExecutionId']\n",
    "            \n",
    "        def wait_for_query_completion(query_execution_id):\n",
    "            while True:\n",
    "                response = athena_client.get_query_execution(\n",
    "                    QueryExecutionId=query_execution_id\n",
    "                )\n",
    "                state = response['QueryExecution']['Status']['State']\n",
    "                \n",
    "                if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "                    return state\n",
    "                    \n",
    "                time.sleep(2)\n",
    "            \n",
    "        # Wait for query completion\n",
    "        state = wait_for_query_completion(query_execution_id)\n",
    "\n",
    "        if state == 'SUCCEEDED':\n",
    "            # Get query results\n",
    "            results = athena_client.get_query_results(\n",
    "                QueryExecutionId=query_execution_id\n",
    "            )\n",
    "            # Assuming you have a database connection and cursor setup\n",
    "            # cursor.execute(sql)\n",
    "            # results = cursor.fetchall()\n",
    "            \n",
    "            database_structure = []\n",
    "            table_dict = {}\n",
    "\n",
    "            # Skip the header row\n",
    "            rows = results['ResultSet']['Rows'][1:]\n",
    "\n",
    "            for row in rows:\n",
    "                # Extract values from the Data structure\n",
    "                table_name = row['Data'][0]['VarCharValue']\n",
    "                column_name = row['Data'][1]['VarCharValue']\n",
    "                data_type = row['Data'][2]['VarCharValue']\n",
    "                \n",
    "                # Initialize table if not exists\n",
    "                if table_name not in table_dict:\n",
    "                    table_dict[table_name] = []\n",
    "                \n",
    "                # Append column information\n",
    "                table_dict[table_name].append((column_name, data_type))\n",
    "\n",
    "            # Convert to the desired format\n",
    "            for table_name, columns in table_dict.items():\n",
    "                database_structure.append({\n",
    "                    \"table_name\": table_name,\n",
    "                    \"columns\": columns\n",
    "                })\n",
    "\n",
    "            return database_structure\n",
    "\n",
    "        else:\n",
    "            raise Exception(f\"Query failed with state: {state}\")\n",
    "    except Exception as e:\n",
    "            print(f\"Error getting schema: {e}\")\n",
    "            raise\n",
    "\n",
    "def generate_dataset(input_file: str, output_file: str, athena_client):\n",
    "    \"\"\"\n",
    "    Generate dataset with ground truth answers in trajectory format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read input file\n",
    "        with open(input_file, 'r') as f:\n",
    "            questions_data = json.load(f)\n",
    "        \n",
    "        # Initialize trajectories dictionary\n",
    "        trajectories = {}\n",
    "        \n",
    "        # Process each question\n",
    "        for idx, item in enumerate(questions_data):\n",
    "\n",
    "\n",
    "            # Break for testing purposes!\n",
    "            if idx == 5:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            question_id = item.get('question_id', 0)\n",
    "            question = item['question']\n",
    "            sql_query = item['SQL']\n",
    "            \n",
    "            print(f\"\\nProcessing question {question_id}: {question}\")\n",
    "            \n",
    "            # Get table schema\n",
    "            sql_context = get_schema(athena_client)\n",
    "            # Run query\n",
    "            query_results = run_query(sql_query.replace('`','\"'),athena_client)\n",
    "            if query_results is not None:\n",
    "                # Generate answer with formatted response\n",
    "                response = generate_ground_truth_answer(\n",
    "                    question_id=question_id,\n",
    "                    question=question,\n",
    "                    sql_query=sql_query,\n",
    "                    sql_context=str(sql_context),\n",
    "                    query_results=query_results\n",
    "                )\n",
    "                \n",
    "                if response:\n",
    "                    # Create trajectory key\n",
    "                    trajectory_key = f\"Trajectory{idx + 1}\"\n",
    "                    \n",
    "                    # Format the response for this trajectory\n",
    "                    trajectory_response = [response]\n",
    "                    \n",
    "                    # Add to trajectories dictionary\n",
    "                    trajectories[trajectory_key] = trajectory_response\n",
    "                    print(f\"Generated ground truth for question {question_id}\")\n",
    "            \n",
    "        # Write results to output file\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(trajectories, f, indent=2)\n",
    "            \n",
    "        print(f\"\\nProcessed {len(trajectories)} questions. Results saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating dataset: {e}\")\n",
    "\n",
    "INPUT_FILE = \"input.json\"\n",
    "OUTPUT_FILE = \"text2sql_data_file_auto.json\"\n",
    "\n",
    "athena_client = boto3.client('athena')\n",
    "\n",
    "generate_dataset(INPUT_FILE, OUTPUT_FILE,athena_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
