{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample RAG Agent Walkthrough\n",
    "\n",
    "This notebook will walk users through setting up a sample RAG Agent and running it against the Hugging Face 'rag-mini-wikipedia' dataset (https://huggingface.co/datasets/rag-datasets/rag-mini-wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure the latest version of boto3 is shown below\n",
    "\n",
    "##### If not then run through setup_environment.ipynb in the 0-Notebook-environment/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3==1.37.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in environment variables to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve import path\n",
    "%store -r IMPORTS_PATH\n",
    "\n",
    "# Retrieve account info\n",
    "%store -r account_id\n",
    "%store -r region\n",
    "\n",
    "# Retrieve model lists\n",
    "%store -r agent_foundation_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve imports environment variable and bring libraries into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported necessary libraries into notebook\n"
     ]
    }
   ],
   "source": [
    "%run $IMPORTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "This notebook assumes that you have gone through the notebook environment setup in the 0-Notebook-environment/ folder and have set up a Langfuse project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Hugging Face 'rag-mini-wikipedia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves dataset corpus using Datasets Python library\n",
    "\n",
    "ds_corpus = load_dataset(\"rag-datasets/rag-mini-wikipedia\", \"text-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write text corpus to file and upload to Amazon S3 to use as data source for knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now view the whole Wikipedia corpus in mini_wiki.txt\n"
     ]
    }
   ],
   "source": [
    "# Write whole corpus to a .txt file\n",
    "\n",
    "with open('mini_wiki.txt', 'w') as f:\n",
    "    f.write(str(ds_corpus['passages']['passage']))\n",
    "\n",
    "print(\"You can now view the whole Wikipedia corpus in mini_wiki.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'wiki_bucket_name' (str)\n",
      "Created bucket with name 'rag-mini-wiki-861276117215-fba410' in region 'us-west-2'\n"
     ]
    }
   ],
   "source": [
    "# Create Amazon S3 bucket and upload .txt. file to Amazon S3 bucket\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "wiki_bucket_name = f\"rag-mini-wiki-{account_id}-{uuid.uuid4().hex[:6]}\"\n",
    "\n",
    "s3_client.create_bucket(\n",
    "    Bucket=wiki_bucket_name,\n",
    "    CreateBucketConfiguration={\n",
    "        'LocationConstraint': region\n",
    "    }\n",
    ")\n",
    "\n",
    "%store wiki_bucket_name\n",
    "\n",
    "print(\"Created bucket with name '{}' in region '{}'\".format(wiki_bucket_name, region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded corpus to 'rag-mini-wiki-861276117215-fba410'\n"
     ]
    }
   ],
   "source": [
    "# Place .txt corpus in S3 bucket\n",
    "\n",
    "s3_client.upload_file('mini_wiki.txt', wiki_bucket_name, 'mini_wiki.txt')\n",
    "\n",
    "print(\"Uploaded corpus to '{}'\".format(wiki_bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bedrock Knowledge Base\n",
    "#### Follow the steps below to create a Bedrock Knowledge Base in the AWS Console manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Navigate to the 'Amazon Bedrock' service in the AWS Console and navigate to the 'Knowledge Bases' section\n",
    "\n",
    "Step 2: Click 'Create' and select 'Knowledge Base with vector store'\n",
    "\n",
    "Step 3: Name the Knowledge Base 'mini-wiki-kb' and select the Amazon S3 data source radio button\n",
    "\n",
    "Step 4: Name the data source 'mini-wiki-data' and select the S3 bucket file 'mini_wiki.txt' that was uploaded, \n",
    "        e.x. s3://rag-mini-wikipedia-data-XXXXXXXXXXXX/mini_wiki.txt\n",
    "\n",
    "Step 5: Use the default parsing and default chunking options\n",
    "\n",
    "Step 6: Select the 'Titan Text Embeddings V2' embedding model and create an Amazon OpenSearch Serverless vector store with the quick create option\n",
    "\n",
    "Step 7: Now create the knowledge base\n",
    "\n",
    "Step 8: Manually sync the data source with the knowledge base by clicking on the data source and selecting 'Sync' and wait for the process to finish before proceeding to the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'wiki_kb_id' (str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'X6FJE1ZRYL'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch knowledge base ID\n",
    "\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent\", region)\n",
    "\n",
    "# Call the list_knowledge_bases method\n",
    "response = bedrock_agent_client.list_knowledge_bases()\n",
    "wiki_kb_id = None\n",
    "\n",
    "# Iterate through knowledge bases and find needed one\n",
    "if 'knowledgeBaseSummaries' in response:\n",
    "    for kb in response['knowledgeBaseSummaries']:\n",
    "        if 'mini-wiki-kb' in kb['name']:\n",
    "            wiki_kb_id = kb['knowledgeBaseId']\n",
    "\n",
    "%store wiki_kb_id\n",
    "\n",
    "wiki_kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = 'sample-rag-agent'\n",
    "agent_description = \"RAG agent to run against the Hugging Face 'rag-mini-wikipedia' dataset\"\n",
    "agent_instruction = \"\"\"Use the associated knowledge base to answer questions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DS8G3449MI',\n",
       " 'TSTALIASID',\n",
       " 'arn:aws:bedrock:us-west-2:861276117215:agent-alias/DS8G3449MI/TSTALIASID')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents = AgentsForAmazonBedrock()\n",
    "\n",
    "rag_agent = agents.create_agent(\n",
    "    agent_name,\n",
    "    agent_description,\n",
    "    agent_instruction,\n",
    "    agent_foundation_model,\n",
    "    code_interpretation=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "rag_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DS8G3449MI', 'arn:aws:bedrock:us-west-2:861276117215:agent/DS8G3449MI')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_agent_id = rag_agent[0]\n",
    "rag_agent_arn = f\"arn:aws:bedrock:{region}:{account_id}:agent/{rag_agent_id}\"\n",
    "\n",
    "rag_agent_id, rag_agent_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.associate_kb_with_agent(\n",
    "    rag_agent_id,\n",
    "    \"Hugging Face 'rag-mini-wikipedia' dataset\", \n",
    "    wiki_kb_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test RAG Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke Sample RAG Agent Test Alias to see that it answers question properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request sent to Agent\n",
      "====================\n",
      "Agent processing query now\n",
      "====================\n",
      "Agent Answer: Grace Bedell, an 11-year-old girl, suggested to Lincoln that he grow a beard in 1860.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# Ask example question to agent\n",
    "\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region)\n",
    "\n",
    "session_id:str = str(uuid.uuid1())\n",
    "\n",
    "test_query = \"Who suggested Lincoln grow a beard?\"\n",
    "response = bedrock_agent_runtime_client.invoke_agent(\n",
    "      inputText=test_query,\n",
    "      agentId=rag_agent_id,\n",
    "      agentAliasId=\"TSTALIASID\", \n",
    "      sessionId=session_id,\n",
    "      enableTrace=True, \n",
    "      endSession=False,\n",
    "      sessionState={}\n",
    ")\n",
    "\n",
    "print(\"Request sent to Agent\")\n",
    "print(\"====================\")\n",
    "print(\"Agent processing query now\")\n",
    "print(\"====================\")\n",
    "\n",
    "# Initialize an empty string to store the answer\n",
    "answer = \"\"\n",
    "\n",
    "# Iterate through the event stream\n",
    "for event in response['completion']:\n",
    "    # Check if the event is a 'chunk' event\n",
    "    if 'chunk' in event:\n",
    "        chunk_obj = event['chunk']\n",
    "        if 'bytes' in chunk_obj:\n",
    "            # Decode the bytes and append to the answer\n",
    "            chunk_data = chunk_obj['bytes'].decode('utf-8')\n",
    "            answer += chunk_data\n",
    "\n",
    "# Now 'answer' contains the full response from the agent\n",
    "print(\"Agent Answer: {}\".format(answer))\n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare agent and create alias for use with evaluation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'rag_agent_alias_arn' (str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('K72I4ACIFL',\n",
       " 'arn:aws:bedrock:us-west-2:861276117215:agent-alias/DS8G3449MI/K72I4ACIFL')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_agent_alias_id, rag_agent_alias_arn = agents.create_agent_alias(\n",
    "    rag_agent[0], 'v1'\n",
    ")\n",
    "\n",
    "%store rag_agent_alias_arn\n",
    "rag_agent_alias_id, rag_agent_alias_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input .json file for all RAG using ground truth provided by Hugging Face dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the option to specify the number of question to generate. \n",
    "\n",
    "#### Default is 10, set to -1 to run through all questions, or specify to any other desired number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_questions = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input json data file for evaluation framework and place so it can be run by evaluation framework by user\n",
    "\n",
    "ds_qa = load_dataset(\"rag-datasets/rag-mini-wikipedia\", \"question-answer\")\n",
    "\n",
    "input_data_dict = {}\n",
    "\n",
    "# Iterate through all elements in dataset\n",
    "for index, data in enumerate(ds_qa['test']):\n",
    "\n",
    "    # Extract desired number of questions\n",
    "    if number_questions != -1:\n",
    "        if index == number_questions:\n",
    "            break\n",
    "\n",
    "    qa_pair = {\n",
    "        \"question_id\": data['id'],\n",
    "        \"question_type\": \"RAG\",\n",
    "        \"question\": data['question'],\n",
    "        \"ground_truth\": data['answer']\n",
    "    }   \n",
    "    input_data_dict[\"Trajectory{}\".format(index)] = [qa_pair]\n",
    "\n",
    "# Save to JSON file\n",
    "with open('rag_data_file_auto.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(input_data_dict, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Bedrock Agent Evaluation Framework on the newly created sample RAG agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Navigate to config_tpl.py at the root of the repository and create a copy named 'config.py'\n",
    "\n",
    "Step 2: Fill in config.py with the below information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT_ID='DS8G3449MI'\n",
      "AGENT_ALIAS_ID='K72I4ACIFL'\n",
      "DATA_FILE_PATH='blog_sample_agents/1-Sample-rag-agent/rag_data_file_auto.json'\n"
     ]
    }
   ],
   "source": [
    "print(\"AGENT_ID='{}'\".format(rag_agent_id))\n",
    "print(\"AGENT_ALIAS_ID='{}'\".format(rag_agent_alias_id))\n",
    "print(\"DATA_FILE_PATH='{}'\".format(\"blog_sample_agents/1-Sample-rag-agent/rag_data_file_auto.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Input the keys provided by your Langfuse project into the 'config.py' file\n",
    "\n",
    "Step 4: Run the evaluation framework against the dataset by opening a terminal, navigate to the root of the repository, and run 'python3 driver.py' \n",
    "\n",
    "Step 5: Look at your Langfuse project's dashboard and traces to see the evaluation results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
